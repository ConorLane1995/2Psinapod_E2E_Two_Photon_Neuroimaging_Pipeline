{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23cb3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e8895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import general functions from preprocess_utils file.\n",
    "from preprocess_utils import load_config_from_json\n",
    "\n",
    "# Create a class to extract the required elements from the config.json that are used here, and load as config. \n",
    "@dataclass\n",
    "class Config:\n",
    "    RecordingFolder: str\n",
    "    AnalysisFile: str\n",
    "    CellMatchFile: str\n",
    "    RecordingFolder2: str\n",
    "\n",
    "# If config.json is in the parent directory\n",
    "config_path = os.path.join('..', 'config.json')\n",
    "config = load_config_from_json(config_path, Config)\n",
    "\n",
    "BASE_PATH = config.RecordingFolder\n",
    "BASE_PATH_2 = config.RecordingFolder2\n",
    "CELL_DICT_FILE = config.AnalysisFile\n",
    "CELL_DICT_FILE_OUT = CELL_DICT_FILE\n",
    "CELL_MATCH_FILE = config.CellMatchFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08232e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create file paths to load the pre and post recording cell dictionaries.\n",
    "dict_path_1 = BASE_PATH + 'cells.pkl'\n",
    "dict_path_2 = BASE_PATH_2 + 'cells.pkl'\n",
    "\n",
    "iscell_1 = BASE_PATH + 'iscell.npy'\n",
    "iscell_2 = BASE_PATH_2 + 'iscell.npy'\n",
    "\n",
    "# Open cell dictionaries\n",
    "with open(dict_path_1, 'rb') as f:\n",
    "    cell_dict_1 = pickle.load(f)\n",
    "\n",
    "with open(dict_path_2, 'rb') as f:\n",
    "    cell_dict_2 = pickle.load(f)\n",
    "\n",
    "    \n",
    "iscell_1 = np.load(iscell_1)\n",
    "iscell_2 = np.load(iscell_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ce41742",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_indices_1 = (iscell_1[:,0] == 1).nonzero()\n",
    "ROI_indices_1 = ROI_indices_1[0] # extracting the first part of the tuple\n",
    "cell_IDs_1 = ROI_indices_1 + 1 # add 1 so we don't have zero indexing\n",
    "\n",
    "# print(cell_IDs_1[436])\n",
    "\n",
    "ROI_indices_2 = (iscell_2[:,0] == 1).nonzero()\n",
    "ROI_indices_2 = ROI_indices_2[0] # extracting the first part of the tuple\n",
    "cell_IDs_2 = ROI_indices_2 + 1 # add 1 so we don't have zero indexing\n",
    "\n",
    "# print(cell_IDs_2[255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "802122a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a NumPy array\n",
    "matched_cells_output = np.genfromtxt(BASE_PATH_2 + CELL_MATCH_FILE, delimiter=',', skip_header=0)\n",
    "matched_cells_output = matched_cells_output.astype(int) -1  # Subtract 1 and convert to int (we subtract 1 here as the csv is created in MATLAB,\n",
    "                                              # which doesn't have zero indexing).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ec11a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the two columns\n",
    "column_0 = matched_cells_output[:, 0]\n",
    "column_1 = matched_cells_output[:, 1]\n",
    "\n",
    "# Make sure the indices donâ€™t go out of range\n",
    "valid_idx_mask = (column_0 < len(cell_IDs_1)) & (column_1 < len(cell_IDs_2))\n",
    "\n",
    "# Apply mask\n",
    "column_0 = column_0[valid_idx_mask]\n",
    "column_1 = column_1[valid_idx_mask]\n",
    "\n",
    "# Map to Suite2p-style cell IDs (which are used in cell_dicts)\n",
    "cell_array = np.zeros((len(column_0), 2), dtype=int)\n",
    "cell_array[:, 0] = cell_IDs_1[column_0]\n",
    "cell_array[:, 1] = cell_IDs_2[column_1]\n",
    "\n",
    "# Filter matched pairs to only those where both cells are in the dictionaries\n",
    "cell_array_filtered = np.array([\n",
    "    [pre, post] for pre, post in cell_array\n",
    "    if pre in cell_dict_1 and post in cell_dict_2\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9ae58b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the matched_cells array in the FIRST cell of each dictionary (saved inside sub_dict so that it doesn't mess up code that iterates through the dict cells)\n",
    "\n",
    "cell_dict_1[next(iter(cell_dict_1))]['matched_cells'] = cell_array_filtered\n",
    "cell_dict_2[next(iter(cell_dict_2))]['matched_cells'] = cell_array_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0da1be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BASE_PATH+'cells.pkl','wb') as f:\n",
    "        pickle.dump(cell_dict_1,f)\n",
    "\n",
    "with open(BASE_PATH_2+'cells.pkl','wb') as f:\n",
    "        pickle.dump(cell_dict_2,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
